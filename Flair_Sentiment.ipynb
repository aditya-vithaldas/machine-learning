{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair - Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3AjHaU5spUaerGK4f2qmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vithaldas/machine-learning/blob/master/Flair_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c0qMF6RGaDw",
        "outputId": "ab20f41e-8de5-4373-e5cf-507a8e37fb35"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.9-py3-none-any.whl (319 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 319 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 42.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.4 MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting more-itertools~=8.8.0\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.9.0+cu102)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.0\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 27.4 MB/s \n",
            "\u001b[?25hCollecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 772 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 44.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect, wikipedia-api\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=3539ffc7fdb5101825a90a270ce9d0395f07d6724e54ca8fe46170f93bbf374d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=e22a54b318c7ea64b6fa7b99a79930f8c7a38b537f6c904d5187341a189dadf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=b37d27f044d86aad5059624cc359dac3ee425b76aa8c4ec3ee150adabf6f7919\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=b8fabe219d8d72e4edc83b114e7d4155aff98a1942c6ec58abe3e98d467db24a\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=57f79dae407647112850ec6c8796e4a783d128f50db8d5424d92471a40c52369\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=12b815f7cc350b76a27496c3aa3d1616fecb85b4720203535bc6be7e19ea0966\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=84e1e7e7d64f9ff0ead54c37255094a350ff9aa6aab7e71630c2209d3c8c8bc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13475 sha256=d299d6c87b8b6b7fafd9d5d334c20d5fcadfea245ddf95125e067b43005cfd55\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect wikipedia-api\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.1\n",
            "    Uninstalling importlib-metadata-4.8.1:\n",
            "      Successfully uninstalled importlib-metadata-4.8.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.10.0\n",
            "    Uninstalling more-itertools-8.10.0:\n",
            "      Successfully uninstalled more-itertools-8.10.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.9 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.17 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.46 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.11.2 wikipedia-api-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGwLfM5iGb76",
        "outputId": "87da861f-d4a9-4b18-9599-4f781ab54035"
      },
      "source": [
        "#initialize\n",
        "import flair\n",
        "model = flair.models.TextClassifier.load(\"en-sentiment\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04 16:25:06,625 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVllxWBaH2s5",
        "outputId": "e9d3a32a-3165-4d73-8ff8-a40fbbdd15ea"
      },
      "source": [
        "#tokenize\n",
        "text = \"I like you!\"\n",
        "sentence = flair.data.Sentence(text)\n",
        "print (sentence.to_tokenized_string())\n",
        "print (sentence)\n",
        "#process model with flair\n",
        "model.predict(sentence)\n",
        "print (sentence) #weird, but the results get added to the sentence, not to output\n",
        "#format output\n",
        "text = \"I hate it\"\n",
        "sentence = flair.data.Sentence(text)\n",
        "model.predict(sentence)\n",
        "print (sentence)\n",
        "\n",
        "print (sentence.get_labels()[0].score)\n",
        "print (sentence.get_labels()[0].value)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like you !\n",
            "Sentence: \"I like you !\"   [− Tokens: 4]\n",
            "Sentence: \"I like you !\"   [− Tokens: 4  − Sentence-Labels: {'label': [POSITIVE (0.9928)]}]\n",
            "Sentence: \"I hate it\"   [− Tokens: 3  − Sentence-Labels: {'label': [NEGATIVE (1.0)]}]\n",
            "0.9999920129776001\n",
            "NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbP1aW9rXuew"
      },
      "source": [
        "#LETS TRY TO USE TRANSFORMERS LIBRARY\n",
        "#!pip install transformers\n",
        "model_name = \"ProsusAI/finbert\"\n",
        "from transformers import BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68qbfmNQZdA4",
        "outputId": "76c45889-fddc-4b2b-ac7e-d5be29edaf03"
      },
      "source": [
        "#Tokenize\n",
        "txt = (\"This is actually really bad \")\n",
        "tokens = tokenizer.encode_plus(txt, max_length=512, \n",
        "                               truncation=True,\n",
        "                               padding='max_length',\n",
        "                               add_special_tokens=True, \n",
        "                               return_tensors='pt') #pytorch tensors)\n",
        "#Token IDs -> models\n",
        "output = model(**tokens)\n",
        "output[0]\n",
        "#Model activation to rpobabilities\n",
        "import torch.nn.functional as F\n",
        "probs = F.softmax(output[0], dim=-1)\n",
        "\n",
        "#Argmax of taht\n",
        "import torch\n",
        "pred = torch.argmax(probs)\n",
        "pred.item()\n",
        "#"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3djWrfi8Yv6C"
      },
      "source": [
        ""
      ]
    }
  ]
}