{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy Testing Playground.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwUthcRmHseoH7jWY1lemt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vithaldas/machine-learning/blob/master/Spacy_Testing_Playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJDwJtY13kIw",
        "outputId": "b96899fa-ddf7-47fa-a0e3-17fc8499f0b6"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"hello there\")\n",
        "print (doc)\n",
        "pattern = [{'LOWER': \"l'oreal\", 'POS': 'NOUN'}, {'LOWER': 'dove', 'POS': 'NOUN'}, {'LOWER': 'pantene', 'POS': 'NOUN'}, {'LOWER': 'khadi', 'POS': 'NOUN'}, {'LOWER': 'head & shoulders', 'POS': 'NOUN'}, {'LOWER': 'tresemme', 'POS': 'NOUN'}, {'LOWER': 'schwarzkopf', 'POS': 'NOUN'}, {'LOWER': 'khadi herbal', 'POS': 'NOUN'}, {'LOWER': 'kerastase', 'POS': 'NOUN'}, {'LOWER': 'srotam', 'POS': 'NOUN'}, {'LOWER': 'khadi natural', 'POS': 'NOUN'}, {'LOWER': 'paul mitchell', 'POS': 'NOUN'}, {'LOWER': 'garnier', 'POS': 'NOUN'}, {'LOWER': 'khadi mauri', 'POS': 'NOUN'}, {'LOWER': 'herbal essences', 'POS': 'NOUN'}, {'LOWER': 'sunsilk', 'POS': 'NOUN'}, {'LOWER': 'leafveda', 'POS': 'NOUN'}, {'LOWER': 'wella professionals', 'POS': 'NOUN'}, {'LOWER': 'biotique', 'POS': 'NOUN'}, {'LOWER': 'khadi pure', 'POS': 'NOUN'}, {'LOWER': 'park avenue', 'POS': 'NOUN'}, {'LOWER': 'matrix', 'POS': 'NOUN'}, {'LOWER': 'suave', 'POS': 'NOUN'}, {'LOWER': 'redken', 'POS': 'NOUN'}, {'LOWER': 'clinic plus', 'POS': 'NOUN'}, {'LOWER': 'khadi natural herbal', 'POS': 'NOUN'}, {'LOWER': 'ogx', 'POS': 'NOUN'}, {'LOWER': 'khadi organique', 'POS': 'NOUN'}, {'LOWER': 'himalaya', 'POS': 'NOUN'}, {'LOWER': 'goldwell', 'POS': 'NOUN'}, {'LOWER': 'davines', 'POS': 'NOUN'}, {'LOWER': 'tigi', 'POS': 'NOUN'}, {'LOWER': 'head shoulders', 'POS': 'NOUN'}, {'LOWER': 'danfree', 'POS': 'NOUN'}, {'LOWER': 'tresemmé', 'POS': 'NOUN'}, {'LOWER': 'chik protein', 'POS': 'NOUN'}, {'LOWER': 'patanjall', 'POS': 'NOUN'}, {'LOWER': 'patanjali', 'POS': 'NOUN'}, {'LOWER': 'wheezal', 'POS': 'NOUN'}, {'LOWER': \"l'oréal\", 'POS': 'NOUN'}, {'LOWER': 'nyle', 'POS': 'NOUN'}, {'LOWER': 'ayush', 'POS': 'NOUN'}, {'LOWER': 'mamaearth', 'POS': 'NOUN'}, {'LOWER': 'mukti gold', 'POS': 'NOUN'}, {'LOWER': 'head& shoulders', 'POS': 'NOUN'}, {'LOWER': 'herbal essences', 'POS': 'NOUN'}, {'LOWER': 'meera', 'POS': 'NOUN'}, {'LOWER': '7 days', 'POS': 'NOUN'}, {'LOWER': 'sebamed', 'POS': 'NOUN'}, {'LOWER': 'ayur', 'POS': 'NOUN'}, {'LOWER': 'vip', 'POS': 'NOUN'}, {'LOWER': 'johnson', 'POS': 'NOUN'}, {'LOWER': 'biolage', 'POS': 'NOUN'}, {'LOWER': 'nuzen', 'POS': 'NOUN'}, {'LOWER': 'salon professional', 'POS': 'NOUN'}, {'LOWER': 'scalpe', 'POS': 'NOUN'}, {'LOWER': 'ketoscalp', 'POS': 'NOUN'}, {'LOWER': 'keto scalp', 'POS': 'NOUN'}, {'LOWER': 'good vibes', 'POS': 'NOUN'}, {'LOWER': 'wishcare', 'POS': 'NOUN'}, {'LOWER': 'gulbadan', 'POS': 'NOUN'}, {'LOWER': 'wella professionals', 'POS': 'NOUN'}, {'LOWER': 'wella', 'POS': 'NOUN'}, {'LOWER': 'sesa', 'POS': 'NOUN'}, {'LOWER': 'siyu', 'POS': 'NOUN'}, {'LOWER': 'wow', 'POS': 'NOUN'}, {'LOWER': 'rootz', 'POS': 'NOUN'}, {'LOWER': 'oshea', 'POS': 'NOUN'}, {'LOWER': 'montana', 'POS': 'NOUN'}, {'LOWER': 'kozicare', 'POS': 'NOUN'}, {'LOWER': 'chicco', 'POS': 'NOUN'}, {'LOWER': 'vatika', 'POS': 'NOUN'}, {'LOWER': 'kesh king', 'POS': 'NOUN'}, {'LOWER': 'keraglo', 'POS': 'NOUN'}, {'LOWER': 'tresemm', 'POS': 'NOUN'}, {'LOWER': \"l'or\", 'POS': 'NOUN'}, {'LOWER': ' ayur ', 'POS': 'NOUN'}, {'LOWER': 'beard wash', 'POS': 'NOUN'}]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5PS7WJG5QUd"
      },
      "source": [
        "#Language class with the English model 'en_core_web_sm' is loaded\n",
        "#!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")#instantiate a new Matcher class object \n",
        "matcher = Matcher(nlp.vocab)\n",
        "#define the pattern\n",
        "pattern = [{'LOWER': 'computer', 'POS': 'NOUN'},\n",
        "             {'POS':{'NOT_IN': ['VERB']}}]\n",
        "#add the pattern to the previously created matcher object\n",
        "matcher.add(\"BRAND\", None, pattern)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "5b3tWDKY5bBl",
        "outputId": "094745fb-2387-4661-ff27-3ff2d9199e7e"
      },
      "source": [
        "from spacy import displacy\n",
        "#string = \"This is dove shampoo in the \"\n",
        "\n",
        "#string = string.Description\n",
        "\n",
        "string = \"L'oreal is a great shampoo for Beard face wash and Pantene also pantene and dove and DOVE and Dove. Nt working Khadi and khadi\"\n",
        "print (string)\n",
        "ret = nlp.pipeline \n",
        "print (ret[2][1].labels)\n",
        "print (ret[2][1].label_data)\n",
        "doc = nlp(string)\n",
        "matches = matcher(doc)#print the matched results and extract out the results\n",
        "for match_id, start, end in matches:\n",
        "    # Get the string representation \n",
        "    string_id = nlp.vocab.strings[match_id]  \n",
        "    #span = doc[start:end]  # The matched span\n",
        "    span = Span(doc, start, end, label=match_id)\n",
        "    doc.ents = list(doc.ents) + [span]  # add span to doc.ents\n",
        "    print(match_id, string_id, start, end, span.text)\n",
        "\n",
        "displacy.render(doc,style=\"ent\",jupyter=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'oreal is a great shampoo for Beard face wash and Pantene also pantene and dove and DOVE and Dove. Nt working Khadi and khadi\n",
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5c9149af40d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#print the matched results and extract out the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.pipeline.pipes.EntityRecognizer' object has no attribute 'label_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKacdsUv3r1U",
        "outputId": "ba48ded9-f077-4375-c288-7ed7e358d519"
      },
      "source": [
        "print (nlp.pipeline)\n",
        "from spacy import Matcher\n",
        "\n",
        "text = [\"Hello there, doing random stuff, O am Aditya Vithaldas and this is Dove shampoo\"]\n",
        "for doc in nlp.pipe(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"ner\"]):\n",
        "    print (doc)\n",
        "    # Do something with the doc here\n",
        "    print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7fe7a01296d0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7fe7a0f3ede0>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7fe79b1bd670>)]\n",
            "Hello there, doing random stuff, O am Aditya Vithaldas and this is Dove shampoo\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NEKJoLG8QSp",
        "outputId": "6713dddb-ec79-4aec-e69a-f062e576de09"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "list_of_drugs = ['insulin', 'aspirin', 'humalog', 'lantus', 'tamsulosin', 'amlodipine']\n",
        "list_of_shampoos = ['dove','loreal','khadi']\n",
        "\n",
        "class EntityMatcher(object):\n",
        "    name = 'entity_matcher'\n",
        "\n",
        "    def __init__(self, nlp, terms, label):\n",
        "        patterns = [nlp(term) for term in terms]\n",
        "        self.matcher = PhraseMatcher(nlp.vocab)\n",
        "        self.matcher.add(label, None, *patterns)\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        matches = self.matcher(doc)\n",
        "        spans = []\n",
        "        for label, start, end in matches:\n",
        "            span = Span(doc, start, end, label=label)\n",
        "            spans.append(span)\n",
        "        doc.ents = spans\n",
        "        return doc\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "string = \"L'oreal is a great shampoo for Beard face wash and Pantene also pantene and dove and DOVE and Dove. Nt working Khadi and khadi\"\n",
        "\n",
        "doc = nlp(u'Apple is looking at buying U.K. aspirin and tamsulosin startup for $1 billion')\n",
        "doc = nlp(string)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "entity_matcher = EntityMatcher(nlp, list_of_drugs, 'DRUG')\n",
        "entity_matcher = EntityMatcher(nlp, list_of_shampoos, 'SHAMPOO')\n",
        "\n",
        "#nlp.add_pipe(entity_matcher,  before='ner')\n",
        "nlp.add_pipe(entity_matcher)\n",
        "print(nlp.pipe_names)\n",
        "doc = nlp(u'Apple is looking at buying U.K. startup for production of aspirin and tamsulosin for $1 billion')\n",
        "doc = nlp(string)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'oreal 0 7 ORG\n",
            "Beard 31 36 PRODUCT\n",
            "Pantene 51 58 PERSON\n",
            "DOVE 85 89 PERSON\n",
            "Dove 94 98 PERSON\n",
            "Khadi 111 116 PERSON\n",
            "['tagger', 'parser', 'ner', 'entity_matcher']\n",
            "dove 76 80 SHAMPOO\n",
            "khadi 121 126 SHAMPOO\n"
          ]
        }
      ]
    }
  ]
}